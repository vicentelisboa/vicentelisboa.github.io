<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Topic classification of Yahoo Answers using deep learning models | Vicente Lisboa</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="By Eric Frey, Davis Thomas, Vicente Lisboa, Chunfeng Wang">
    <meta name="generator" content="Hugo 0.111.3">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="https://vicentelisboa.github.io/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="Topic classification of Yahoo Answers using deep learning models" />
<meta property="og:description" content="By Eric Frey, Davis Thomas, Vicente Lisboa, Chunfeng Wang" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://vicentelisboa.github.io/post/project--2/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-04-02T10:58:08-04:00" />
<meta property="article:modified_time" content="2023-04-02T10:58:08-04:00" /><meta property="og:site_name" content="Vicente Lisboa" />
<meta itemprop="name" content="Topic classification of Yahoo Answers using deep learning models">
<meta itemprop="description" content="By Eric Frey, Davis Thomas, Vicente Lisboa, Chunfeng Wang"><meta itemprop="datePublished" content="2023-04-02T10:58:08-04:00" />
<meta itemprop="dateModified" content="2023-04-02T10:58:08-04:00" />
<meta itemprop="wordCount" content="1266">
<meta itemprop="keywords" content="Neural networks," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Topic classification of Yahoo Answers using deep learning models"/>
<meta name="twitter:description" content="By Eric Frey, Davis Thomas, Vicente Lisboa, Chunfeng Wang"/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  <header class="cover bg-top" style="background-image: url('https://vicentelisboa.github.io/images/background_8.jpg');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://vicentelisboa.github.io/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Vicente Lisboa
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://vicentelisboa.github.io/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://vicentelisboa.github.io/contact/" title="Contact page">
              Contact
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://vicentelisboa.github.io/post/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
    
    <a href="https://www.linkedin.com/in/vicente-lisboa/" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://github.com/vicentelisboa" target="_blank" rel="noopener" class="GitHub ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <div class="f2 f1-l fw2 white-90 mb0 lh-title">Topic classification of Yahoo Answers using deep learning models</div>
          
            <div class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              By Eric Frey, Davis Thomas, Vicente Lisboa, Chunfeng Wang
            </div>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
      
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://vicentelisboa.github.io/post/project--2/&amp;title=Topic%20classification%20of%20Yahoo%20Answers%20using%20deep%20learning%20models" class="ananke-social-link linkedin no-underline" aria-label="share on LinkedIn">
        
        <span class="icon"> <svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
        
      </a>
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Topic classification of Yahoo Answers using deep learning models</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-04-02T10:58:08-04:00">April 2, 2023</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h2 id="b-stylefont-size-50pxclassification-of-yahoo-answersb"><!-- raw HTML omitted -->Classification of Yahoo Answers<!-- raw HTML omitted --></h2>
<h2 id="b-stylefont-size-16pxintroductionb"><!-- raw HTML omitted -->Introduction<!-- raw HTML omitted --></h2>
<p>The goal of this project is to classify Yahoo! Answers posts into their respective topics. We use a dataset provided by Huggingface, which includes 2 million Yahoo! Answers posts categorized into ten topics. We select three topics - Health, Science &amp; Mathematics, and Society &amp; Culture - and sample 100,000 posts from the dataset for training and testing.</p>
<p>We apply several models to the task of classification, including rule-based models, traditional machine learning models, and deep learning models. We evaluate the performance of each model using metrics such as precision, recall, and accuracy.</p>
<h2 id="b-stylefont-size-24pxhow-to-run-this-codeb"><!-- raw HTML omitted -->How to run this code?<!-- raw HTML omitted --></h2>
<p>The summary.ipynb notebook contains an overview of the models used. This comes from combining the notebooks in the src folder, namely data_preprocessing.ipynb, baseline_models.ipynb RNN.ipynb, and BERT.ipynb. Please note that you may need to change the path(s) to the &lsquo;yahoo_train.csv&rsquo; file after writing the preprocessed data to a csv, depending on your specific directory.</p>
<h2 id="b-stylefont-size-32pxdatab"><!-- raw HTML omitted -->Data<!-- raw HTML omitted --></h2>
<p>The Yahoo! Answers dataset includes ten balanced topics/classes. As described in the Introduction section, we select the first three topics in order to be less constrained by computational power and allow for more exploration of the data and models. These topics are: Health, Science &amp; Mathematics, and Society &amp; Culture. We also sample 100,000 rows from the dataset of 2 million. We split this sample of 100,000 observations into 70,000 training observations and 30,000 test observations.</p>
<h2 id="b-stylefont-size-28pxpreprocessingb"><!-- raw HTML omitted -->Preprocessing<!-- raw HTML omitted --></h2>
<p>We preprocess the data by performing the following operations:</p>
<ul>
<li>Replace the topic number with its name to have a general understanding about the data</li>
<li>Remove the punctuation and stopwords</li>
<li>Remove the special characters (html tags) e.g &rsquo;&rsquo; , &lsquo;\n&rsquo; with regex</li>
<li>Optional:stemming,lemmatization</li>
<li>Merge title, question and answer into one column</li>
</ul>
<p>We also provide exploratory data analysis (EDA) by plotting histograms of topic distribution, exploring NaN values in the dataset, and generating word clouds of the most frequent words in the dataset and by topic.</p>
<h2 id="b-stylefont-size-32pxmodelsb"><!-- raw HTML omitted -->Models<!-- raw HTML omitted --></h2>
<h2 id="b-stylefont-size-24pxbaseline-modelb"><!-- raw HTML omitted -->Baseline Model<!-- raw HTML omitted --></h2>
<p>A baseline model is a simple model that serves as a starting point for building more complex models. It provides a reference point for evaluating the performance of more sophisticated models. In order to analyze different starting points we defined three different baseline models:</p>
<h2 id="b-stylefont-size-28pxrule-based-modelb"><!-- raw HTML omitted -->Rule-based Model<!-- raw HTML omitted --></h2>
<p>The rule-based model is a simple model that uses a dictionary for each topic with the fifty most common words. For each sentence, the model finds the dictionary with the most coincidences and classifies the text under that topic. We evaluate the model&rsquo;s performance using precision, recall, f1-score, and the confusion matrix.</p>
<h2 id="b-stylefont-size-28pxtf-idf--logistic-regressionb"><!-- raw HTML omitted -->TF-IDF + Logistic Regression<!-- raw HTML omitted --></h2>
<p>The TF-IDF + Logistic Regression model creates a bag of words with Count Vectorizer, applies a TF-IDF transformer, and then runs a Logistic Regression to classify the data. We evaluate the model&rsquo;s performance using precision, recall, and accuracy.</p>
<h2 id="b-stylefont-size-28pxdecision-tree-classifierb"><!-- raw HTML omitted -->Decision Tree Classifier<!-- raw HTML omitted --></h2>
<p>The Decision Tree Classifier model applies a decision tree to classify the data. We evaluate the model&rsquo;s performance using precision, recall, and accuracy.</p>
<h2 id="b-stylefont-size-28pxrnn---lstmb"><!-- raw HTML omitted -->RNN - LSTM<!-- raw HTML omitted --></h2>
<p>To implement RNN, we used the Keras package to create a neural network, by using LSTM layers which are part of the implementation. Embedding layer using Glove is also added to the model to improve the performance. Initially our performance with this was poor, so we added dropout layers, which seems to reduce overfitting, and we got a better performance as a result.</p>
<h2 id="b-stylefont-size-28pxbertb"><!-- raw HTML omitted -->BERT<!-- raw HTML omitted --></h2>
<p>To implement BERT, we used a package called ktrain. One of the pre-trained models included in ktrain is BERT, which stands for Bidirectional Encoder Representations from Transformers. BERT is a type of deep neural network that&rsquo;s been pre-trained on a large corpus of text data, using a technique called masked language modeling. This involves randomly masking out words from a sentence and training the model to predict the masked words based on the surrounding context.</p>
<p>This network took the most time to train, yet in the end it yielded the best results- slightly above our baseline logistic regression model.</p>
<h2 id="b-stylefont-size-28pxevaluation-metricsb"><!-- raw HTML omitted -->Evaluation Metrics<!-- raw HTML omitted --></h2>
<p>We evaluate each model&rsquo;s performance using precision, recall, and accuracy. Precision measures the percentage of true positives among all positive predictions, recall measures the percentage of true positives among all actual positive instances, and accuracy measures the percentage of correct predictions overall.</p>
<h2 id="b-stylefont-size-32pxanalysisb"><!-- raw HTML omitted -->Analysis<!-- raw HTML omitted --></h2>
<p>We provide a comparison of the models based on the average precision, recall, and accuracy for the three classes:</p>
<h2 id="b-stylefont-size-28pxperformance-comparisonb"><!-- raw HTML omitted -->Performance Comparison<!-- raw HTML omitted --></h2>
<table>
<thead>
<tr>
<th>Avg Precision</th>
<th>Avg Recall</th>
<th>Avg Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>Baseline</td>
<td>.880</td>
<td>.880</td>
</tr>
<tr>
<td>RNN</td>
<td>.809</td>
<td>.808</td>
</tr>
<tr>
<td>Bert</td>
<td>.896</td>
<td>.896</td>
</tr>
</tbody>
</table>
<p>Note that for Bert, the state of the art for the Yahoo! Answers dataset is around .77 for 10 classes, though because we are using only three it&rsquo;s not quite comparable.</p>
<h2 id="b-stylefont-size-28pxbaseline-modelb"><!-- raw HTML omitted -->Baseline Model<!-- raw HTML omitted --></h2>
<p>Below we provide the probability of each class for the TF-IDF + Logistic Regression</p>
<p>It&rsquo;s possible to see according to the confusion matrix to the baseline model, that the correct predictions are well-balanced among all three topics.</p>
<figure><img src="https://vicentelisboa.github.io/images/TF_IDF_Logistic_regression.png"/><figcaption>
            <h4>Confusion Matrix of the baseline model</h4>
        </figcaption>
</figure>

<h2 id="b-stylefont-size-28pxrnn-modelb"><!-- raw HTML omitted -->RNN Model<!-- raw HTML omitted --></h2>
<p>From the below confusion matrix we can see that the RNN has well-balanced could be better</p>
<figure><img src="https://vicentelisboa.github.io/images/rnnconfusion.jpg"/><figcaption>
            <h4>Confusion Matrix of the RNN model</h4>
        </figcaption>
</figure>

<h2 id="b-stylefont-size-28pxbert-modelb"><!-- raw HTML omitted -->Bert Model<!-- raw HTML omitted --></h2>
<p>We can see from the confusion matrix that the BERT model did fairly well among all three classes, as the accuracy is well-balanced:</p>
<figure><img src="https://vicentelisboa.github.io/images/BERT_CM.png"/><figcaption>
            <h4>Confusion Matrix of the BERT model</h4>
        </figcaption>
</figure>

<p>This suggests that the model is unbiased, as it doesn&rsquo;t perform particularly bad on any of the classes.</p>
<p>Below we provide a few test prompts, the probability of each class, as well as the class with the highest probability for the BERT model:</p>
<h2 id="b-stylefont-size-32px-discussionb"><!-- raw HTML omitted --> Discussion<!-- raw HTML omitted --></h2>
<p>Here we see BERT outperform RNN and logistic regression. The reason why BERT performs slightly better than logistic regression and RNN could be attributed to its ability to capture more nuanced features and contextual information from the text data. Since BERT is pre-trained on a large corpus of text data, it has a deeper understanding of the language structure and can capture more subtle relationships between words and phrases.</p>
<h2 id="b-stylefont-size-28px-improvement---data-augmentationb"><!-- raw HTML omitted --> Improvement - Data Augmentation<!-- raw HTML omitted --></h2>
<p>Due to computational constraints we only used a subset of the data. As a result, it could be that the BERT model performs better using more training data. To investigate this hypothesis, we sample 150,000 observations from the original dataset, take 70% as the training dataset and train the BERT model once again.</p>
<p>Below is a table comparing the original BERT model as well as the one trained using 70% of 150k samples:</p>
<table>
<thead>
<tr>
<th>Avg Precision</th>
<th>Avg Recall</th>
<th>Avg Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bert (100k sample)</td>
<td>.896</td>
<td>.896</td>
</tr>
<tr>
<td>Bert (150k sample)</td>
<td>.897</td>
<td>.897</td>
</tr>
</tbody>
</table>
<p>We can see that it performs slightly better. Based on this initial increase in the training set, we could expect that the performance would marginally increase by adding additional training data. One way to do this, assuming that additional training data is unavailable, is through synthetic data augmentation. This could take the form of back translation or synonym replacement, to allow for greater generalization.</p>
<h2 id="b-stylefont-size-32px-conclusionb"><!-- raw HTML omitted --> Conclusion<!-- raw HTML omitted --></h2>
<p>Overall, our project achieved promising results in classifying Yahoo! Answers posts into the topics of Health, Science &amp; Mathematics, and Society &amp; Culture. Our best-performing model, BERT, achieved an average precision, recall, and accuracy of .896 for the three classes. We find that this improves slightly when increasing the sample size. However, our study also has several limitations, including the limited sample size and the use of a pre-existing dataset with potential biases and limitations. Also because Yahoo! Answers is a website that&rsquo;s no longer used, this model is limited in the sense that it has no real external application. Future research could explore including all ten classes, additional preprocessing techniques, feature engineering, and model architectures to improve the performance and generalizability of the classification task.</p>
<h2 id="b-stylefont-size-32px-codesb"><!-- raw HTML omitted --> Codes<!-- raw HTML omitted --></h2>
<p><strong>GitHub Repository:</strong> <a href="https://github.com/vicentelisboa/topic_classification_yahoo_answers.git">https://github.com/vicentelisboa/topic_classification_yahoo_answers.git</a></p>
<ul class="pa0">
  
   <li class="list di">
     <a href="https://vicentelisboa.github.io/tags/neural-networks/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">Neural networks</a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="https://vicentelisboa.github.io/post/project--3/">Probability of death and length of stay using MIMIC dataset</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://vicentelisboa.github.io/" >
    &copy;  Vicente Lisboa 2023 
  </a>
    <div>
<div class="ananke-socials">
  
    
    <a href="https://www.linkedin.com/in/vicente-lisboa/" target="_blank" rel="noopener" class="linkedin ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" aria-label="follow on LinkedIn——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
    
    <a href="https://github.com/vicentelisboa" target="_blank" rel="noopener" class="GitHub ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" aria-label="follow on GitHub——Opens in a new window">
      
        <span class="icon"><svg style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>
</span>
      
<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000"  xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;"/>
</svg>
</span></a>
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
